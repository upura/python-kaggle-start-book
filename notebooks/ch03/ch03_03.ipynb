{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a sample code with Japanese comments.\n",
    "\n",
    "# 3.3 Titanicの先へ行く③！　テキストデータに触れてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like kaggle very much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not like kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do really love machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text\n",
       "0            I like kaggle very much\n",
       "1               I do not like kaggle\n",
       "2  I do really love machine learning"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': ['I like kaggle very much',\n",
    "                            'I do not like kaggle',\n",
    "                            'I do really love machine learning']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "bag = vectorizer.fit_transform(df['text'])\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'like': 4, 'kaggle': 2, 'very': 10, 'much': 7, 'do': 0, 'not': 8, 'really': 9, 'love': 5, 'machine': 6, 'learning': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.31544415 0.40619178 0.         0.40619178 0.\n",
      "  0.         0.53409337 0.         0.         0.53409337]\n",
      " [0.43306685 0.33631504 0.43306685 0.         0.43306685 0.\n",
      "  0.         0.         0.56943086 0.         0.        ]\n",
      " [0.34261996 0.26607496 0.         0.45050407 0.         0.45050407\n",
      "  0.45050407 0.         0.         0.45050407 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tf = vectorizer.fit_transform(df['text'])\n",
    "tfidf = transformer.fit_transform(tf)\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'like': 4, 'kaggle': 2, 'very': 10, 'much': 7, 'do': 0, 'not': 8, 'really': 9, 'love': 5, 'machine': 6, 'learning': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "\n",
    "sentences = [d.split() for d in df['text']]\n",
    "model = word2vec.Word2Vec(sentences, size=10, min_count=1, window=2, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04932676, -0.01171829,  0.04239148,  0.01735417, -0.04764815,\n",
       "       -0.03205363, -0.02873827,  0.04682567,  0.04185081,  0.00795709],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('much', 0.31108221411705017),\n",
       " ('really', 0.11813490092754364),\n",
       " ('not', 0.07177764177322388),\n",
       " ('learning', -0.014833025634288788),\n",
       " ('very', -0.03584161400794983),\n",
       " ('do', -0.11829414963722229),\n",
       " ('machine', -0.12069450318813324),\n",
       " ('kaggle', -0.532151997089386),\n",
       " ('love', -0.5468614101409912),\n",
       " ('I', -0.7641928195953369)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'like', 'kaggle', 'very', 'much']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00070634,  0.04390315, -0.03669089,  0.02026465,  0.04046954,\n",
       "         0.02365695,  0.020924  , -0.03109757, -0.04436051, -0.00691835],\n",
       "       [-0.04932676, -0.01171829,  0.04239148,  0.01735417, -0.04764815,\n",
       "        -0.03205363, -0.02873827,  0.04682567,  0.04185081,  0.00795709],\n",
       "       [ 0.03825201, -0.04983004, -0.03085005, -0.0421443 ,  0.04703034,\n",
       "        -0.01274201,  0.00586073, -0.02872854,  0.01241979, -0.03893603],\n",
       "       [-0.01407814, -0.03944685,  0.01979917, -0.00788147,  0.03230685,\n",
       "         0.04465036, -0.01564248,  0.04261149, -0.04766037,  0.03080159],\n",
       "       [ 0.0160588 , -0.04853946,  0.02299253,  0.00940678, -0.04020066,\n",
       "         0.00423941,  0.00689822,  0.02838706, -0.02563218,  0.02724046]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "wordvec = np.array([model.wv[word] for word in df['text'][0].split()])\n",
    "wordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00196009, -0.0211263 ,  0.00352845, -0.00060003,  0.00639158,\n",
       "        0.00555022, -0.00213956,  0.01159962, -0.01267649,  0.00402895],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wordvec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03825201, 0.04390315, 0.04239148, 0.02026465, 0.04703034,\n",
       "       0.04465036, 0.020924  , 0.04682567, 0.04185081, 0.03080159],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(wordvec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
